{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CH01_03.Affine_Functions.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPgvKdMJC1xHKSzRpp92Sqz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krec7748/Fastcampus_DeepLearning/blob/main/CH01_03_Affine_Functions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Affine Function"
      ],
      "metadata": {
        "id": "AwpFUfuGN3vY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgpxnPZ_Nxpq",
        "outputId": "9e202676-92ad-4a14-a92f-1bf07920d72a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========Input/Weight/Bias=========\n",
            "x : \n",
            " shape: (1, 1)\n",
            " value: [[10.]]\n",
            "\n",
            "W : \n",
            " shape: (1, 1)\n",
            " value: [[0.71057546]]\n",
            "\n",
            "B : \n",
            " shape: (1,)\n",
            " value: [0.]\n",
            "\n",
            "\n",
            "========Output/Weight/Bias=========\n",
            "y(Tensorflow): \n",
            " shape: (1, 1)\n",
            " value: [[7.105755]]\n",
            "\n",
            "y(Manual): \n",
            " shape: (1, 1)\n",
            " value: [[7.105755]]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "x = tf.constant([[10.]]) #input setting (Note: input -> matrix shape)\n",
        "dense = Dense(units = 1, activation = \"linear\") #imp.an affine function\n",
        "\n",
        "y_tf = dense(x) #Forward propagation + params initialization\n",
        "\n",
        "W, B = dense.get_weights()\n",
        "y_matmul = tf.linalg.matmul(x, W) + B\n",
        "\n",
        "print('========Input/Weight/Bias=========')\n",
        "print(\"x : \\n shape: {}\\n value: {}\\n\".format(x.shape, x.numpy()))\n",
        "print(\"W : \\n shape: {}\\n value: {}\\n\".format(W.shape, W))\n",
        "print(\"B : \\n shape: {}\\n value: {}\\n\".format(B.shape, B))\n",
        "print()\n",
        "print('========Output/Weight/Bias=========')\n",
        "print(\"y(Tensorflow): \\n shape: {}\\n value: {}\\n\".format(y_tf.shape, y_tf.numpy()))\n",
        "print(\"y(Manual): \\n shape: {}\\n value: {}\\n\".format(y_matmul.shape, y_matmul.numpy()))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Params initalization "
      ],
      "metadata": {
        "id": "k5IlQEiJQ_bk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.initializers import Constant\n",
        "\n",
        "x = tf.constant([[10.]]) #input setting (Note: input -> matrix shape)\n",
        "w, b = tf.constant([[10.]]), tf.constant([[20.]])\n",
        "\n",
        "w_init, b_init = Constant(w), Constant(b)\n",
        "\n",
        "dense = Dense(units = 1,\n",
        "              activation = \"linear\",\n",
        "              kernel_initializer = w_init,\n",
        "              bias_initializer = b_init)\n",
        "\n",
        "y_tf = dense(x)\n",
        "\n",
        "print(y_tf)\n",
        "\n",
        "W, B = dense.get_weights()\n",
        "\n",
        "print(\"W : \\n shape: {}\\n value: {}\\n\".format(W.shape, W))\n",
        "print(\"B : \\n shape: {}\\n value: {}\\n\".format(B.shape, B))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YosK6oX5RETu",
        "outputId": "d4b07a53-500c-4978-827e-cdc5b82e1534"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[120.]], shape=(1, 1), dtype=float32)\n",
            "W : \n",
            " shape: (1, 1)\n",
            " value: [[10.]]\n",
            "\n",
            "B : \n",
            " shape: (1,)\n",
            " value: [20.]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Affine Function with n Features"
      ],
      "metadata": {
        "id": "2bJynsBoSnBb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "x = tf.random.uniform(shape = (1, 10), minval = 0, maxval = 10)\n",
        "\n",
        "dense = Dense(units = 1) #activation default: \"linear\"\n",
        "\n",
        "y_tf = dense(x)\n",
        "W, B = dense.get_weights()\n",
        "\n",
        "y_matmul = tf.linalg.matmul(x, W) + B\n",
        "\n",
        "print('========Input/Weight/Bias=========')\n",
        "print(\"x : \\n shape: {}\\n value: \\n {}\\n\".format(x.shape, x.numpy()))\n",
        "print(\"W : \\n shape: {}\\n value: \\n {}\\n\".format(W.shape, W))\n",
        "print(\"B : \\n shape: {}\\n value: {}\\n\".format(B.shape, B))\n",
        "print()\n",
        "print('========Output/Weight/Bias=========')\n",
        "print(\"y(Tensorflow): \\n shape: {}\\n value: {}\\n\".format(y_tf.shape, y_tf.numpy()))\n",
        "print(\"y(Manual): \\n shape: {}\\n value: {}\\n\".format(y_matmul.shape, y_matmul.numpy()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAqNSMd9SpY5",
        "outputId": "f221155c-1c99-4e51-a59e-c2b6586838ea"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========Input/Weight/Bias=========\n",
            "x : \n",
            " shape: (1, 10)\n",
            " value: \n",
            " [[8.479128  5.2092276 5.501708  8.103451  9.480567  5.4695215 1.7207038\n",
            "  7.6782093 5.703229  8.985534 ]]\n",
            "\n",
            "W : \n",
            " shape: (10, 1)\n",
            " value: \n",
            " [[-0.01212406]\n",
            " [-0.5005395 ]\n",
            " [-0.18577212]\n",
            " [ 0.53700083]\n",
            " [-0.00329876]\n",
            " [ 0.14693314]\n",
            " [-0.35809702]\n",
            " [ 0.70418507]\n",
            " [ 0.12477314]\n",
            " [-0.14017153]]\n",
            "\n",
            "B : \n",
            " shape: (1,)\n",
            " value: [0.]\n",
            "\n",
            "\n",
            "========Output/Weight/Bias=========\n",
            "y(Tensorflow): \n",
            " shape: (1, 1)\n",
            " value: [[5.6344457]]\n",
            "\n",
            "y(Manual): \n",
            " shape: (1, 1)\n",
            " value: [[5.6344457]]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Activation Layer"
      ],
      "metadata": {
        "id": "BAC22Sk2NrPu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.math import exp, maximum\n",
        "from tensorflow.keras.layers import Activation\n",
        "\n",
        "x = tf.random.normal(shape = (1, 5), seed = 2) #input setting\n",
        "\n",
        "#imp. activation\n",
        "sigmoid = Activation(\"sigmoid\")\n",
        "tanh = Activation(\"tanh\")\n",
        "relu = Activation(\"relu\")\n",
        "\n",
        "#Activation function (Tensorflow)\n",
        "y_sigmoid_tf = sigmoid(x)\n",
        "y_tanh_tf = tanh(x)\n",
        "y_relu_tf = relu(x)\n",
        "\n",
        "#Activation function (Manual)\n",
        "y_sigmoid_man = 1 / (1 + exp(-x))\n",
        "y_tanh_man = (exp(x) - exp(-x)) / (exp(x) + exp(-x))\n",
        "y_relu_man = maximum(x, 0)\n",
        "\n",
        "print(\"x \\n shape: {} \\n value: {} \\n\".format(x.shape,x.numpy()))\n",
        "print()\n",
        "print(\"sigmoid(Tensorflow) \\n shape:{} \\n value:{} \\n\".format(y_sigmoid_tf.shape,y_sigmoid_tf.numpy()))\n",
        "print(\"sigmoid(manual) \\n shape:{} \\n value:{} \\n\".format(y_sigmoid_man.shape,y_sigmoid_man.numpy()))\n",
        "print()\n",
        "print(\"Tanh(Tensorflow) \\n shape:{} \\n value:{} \\n\".format(y_tanh_tf.shape,y_tanh_tf.numpy()))\n",
        "print(\"Tanh(manual) \\n shape:{} \\n value:{} \\n\".format(y_tanh_man.shape,y_tanh_man.numpy()))\n",
        "print()\n",
        "print(\"ReLU(Tensorflow) \\n shape:{} \\n value:{} \\n\".format(y_relu_tf.shape,y_relu_tf.numpy()))\n",
        "print(\"ReLU(manual) \\n shape:{} \\n value:{} \\n\".format(y_relu_man.shape,y_relu_man.numpy()))"
      ],
      "metadata": {
        "id": "i9oWtHxhNtZn",
        "outputId": "b2676b35-b211-442e-87c3-c0a4af959a6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x \n",
            " shape: (1, 5) \n",
            " value: [[-0.85811085 -0.19662298  0.13895045 -1.2212768  -0.40341285]] \n",
            "\n",
            "\n",
            "sigmoid(Tensorflow) \n",
            " shape:(1, 5) \n",
            " value:[[0.2977342  0.451002   0.5346818  0.22771186 0.40049264]] \n",
            "\n",
            "sigmoid(manual) \n",
            " shape:(1, 5) \n",
            " value:[[0.2977342  0.45100197 0.5346818  0.22771186 0.40049264]] \n",
            "\n",
            "\n",
            "Tanh(Tensorflow) \n",
            " shape:(1, 5) \n",
            " value:[[-0.69528306 -0.1941277   0.13806304 -0.84003043 -0.3828653 ]] \n",
            "\n",
            "Tanh(manual) \n",
            " shape:(1, 5) \n",
            " value:[[-0.69528306 -0.19412771  0.13806306 -0.8400304  -0.38286537]] \n",
            "\n",
            "\n",
            "ReLU(Tensorflow) \n",
            " shape:(1, 5) \n",
            " value:[[0.         0.         0.13895045 0.         0.        ]] \n",
            "\n",
            "ReLU(manual) \n",
            " shape:(1, 5) \n",
            " value:[[0.         0.         0.13895045 0.         0.        ]] \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Activation in Dense Layer"
      ],
      "metadata": {
        "id": "QkaacmWqP-YB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.math import exp, maximum\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "x = tf.random.normal(shape = (1, 5), seed = 2) #input setting\n",
        "\n",
        "#imp. an affine + activation\n",
        "dense_sigmoid = Dense(units = 1, activation = \"sigmoid\")\n",
        "dense_tanh = Dense(units = 1, activation = \"tanh\")\n",
        "dense_relu = Dense(units = 1, activation = \"relu\")\n",
        "\n",
        "#Calculate activation value (Tensorflow)\n",
        "y_sigmoid_tf = dense_sigmoid(x)\n",
        "y_tanh_tf = dense_tanh(x)\n",
        "y_relu_tf = dense_relu(x)\n",
        "\n",
        "#Define function to get activation value (Manual)\n",
        "def get_manual_activation_value(tf_x, tf_dense_with_activation, activation):\n",
        "    W, B = tf_dense_with_activation.get_weights()\n",
        "    z = tf.linalg.matmul(tf_x, W) + B\n",
        "    if activation == \"sigmoid\":\n",
        "        a = 1 / (1 + exp(-z))\n",
        "    elif activation == \"tanh\":\n",
        "        a = (exp(z) - exp(-z)) / (exp(z) + exp(-z))\n",
        "    elif activation == \"relu\":\n",
        "        a = maximum(z, 0)\n",
        "\n",
        "    return a\n",
        "\n",
        "#Calculate activation value (Manual)\n",
        "y_sigmoid_man = get_manual_activation_value(x, dense_sigmoid, \"sigmoid\")\n",
        "y_tanh_man = get_manual_activation_value(x, dense_tanh, \"tanh\")\n",
        "y_relu_man = get_manual_activation_value(x, dense_relu, \"relu\")\n",
        "\n",
        "\n",
        "#Confirm\n",
        "print(\"<Sigmoid>\")\n",
        "print(\"Activation value(Tensorflow): \\n shape: {} \\n value: {}\\n\".format(y_sigmoid_tf.shape,y_sigmoid_tf.numpy()))\n",
        "print(\"Activation value(manual): \\n shape: {} \\n value: {}\\n\".format(y_sigmoid_man.shape, y_sigmoid_man.numpy()))\n",
        "print()\n",
        "print(\"<Tanh>\")\n",
        "print(\"Activation value(Tensorflow): \\n shape: {} \\n value: {}\\n\".format(y_tanh_tf.shape,y_tanh_tf.numpy()))\n",
        "print(\"Activation value(manual): \\n shape: {} \\n value: {}\\n\".format(y_tanh_man.shape, y_tanh_man.numpy()))\n",
        "print()\n",
        "print(\"<ReLU>\")\n",
        "print(\"Activation value(Tensorflow): \\n shape: {} \\n value: {}\\n\".format(y_relu_tf.shape,y_relu_tf.numpy()))\n",
        "print(\"Activation value(manual): \\n shape: {} \\n value: {}\\n\".format(y_relu_man.shape, y_relu_man.numpy()))"
      ],
      "metadata": {
        "id": "cqQNgX9_QCmU",
        "outputId": "5fd41b9a-76f0-42b6-e1a3-80eeb8edaf84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Sigmoid>\n",
            "Activation value(Tensorflow): \n",
            " shape: (1, 1) \n",
            " value: [[0.43295142]]\n",
            "\n",
            "Activation value(manual): \n",
            " shape: (1, 1) \n",
            " value: [[0.4329514]]\n",
            "\n",
            "\n",
            "<Tanh>\n",
            "Activation value(Tensorflow): \n",
            " shape: (1, 1) \n",
            " value: [[-0.9548702]]\n",
            "\n",
            "Activation value(manual): \n",
            " shape: (1, 1) \n",
            " value: [[-0.95487016]]\n",
            "\n",
            "\n",
            "<ReLU>\n",
            "Activation value(Tensorflow): \n",
            " shape: (1, 1) \n",
            " value: [[0.]]\n",
            "\n",
            "Activation value(manual): \n",
            " shape: (1, 1) \n",
            " value: [[0.]]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Minibatch"
      ],
      "metadata": {
        "id": "mJjAhoWCX9ZR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "N, n_feature = 16, 10 #set input params\n",
        "x = tf.random.normal(shape = (N, n_feature)) #generate minibatch\n",
        "\n",
        "dense = Dense(units = 1, activation = \"relu\") #imp. an AN\n",
        "y = dense(x) #Forward propagation\n",
        "\n",
        "W, B = dense.get_weights() #get weight, bias\n",
        "\n",
        "#print results\n",
        "print(\"shape of x : \", x.shape)\n",
        "print(\"shape of W : \", W.shape)\n",
        "print(\"shape of B : \", B.shape)"
      ],
      "metadata": {
        "id": "VgUay6QRX7DO",
        "outputId": "c2f84207-e3f6-4a5f-dcf9-49a2ddba06d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of x :  (16, 10)\n",
            "shape of W :  (10, 1)\n",
            "shape of B :  (1,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "N, n_feature = 8, 10 #set input params\n",
        "x = tf.random.normal(shape = (N, n_feature)) #generate minibatch\n",
        "\n",
        "dense = Dense(units = 1, activation = \"sigmoid\") #imp. an AN\n",
        "a_tf = dense(x) #forward propagation (Tensorflow)\n",
        "\n",
        "W, B = dense.get_weights() #get weight, bias\n",
        "\n",
        "z_man = tf.linalg.matmul(x, W) + B #forward propagation_01 (Manual) - Affine function\n",
        "a_man = 1 / (1 + exp(-z_man)) #forward propagation_02 (Manual) - Activation function\n",
        "\n",
        "#print results\n",
        "print(\"Output(Tensorflow) : \\n {}\\n\".format(a_tf.numpy()))\n",
        "print(\"Output(Manual) : \\n {}\\n\".format(a_man.numpy()))"
      ],
      "metadata": {
        "id": "JrmDFaOXX7CD",
        "outputId": "0043d3de-aa94-495c-bbc2-479ac28b484b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output(Tensorflow) : \n",
            " [[0.28788725]\n",
            " [0.45299008]\n",
            " [0.84574205]\n",
            " [0.8148756 ]\n",
            " [0.890126  ]\n",
            " [0.42632514]\n",
            " [0.461335  ]\n",
            " [0.48884308]]\n",
            "\n",
            "Output(Manual) : \n",
            " [[0.28788725]\n",
            " [0.45299008]\n",
            " [0.845742  ]\n",
            " [0.8148756 ]\n",
            " [0.89012593]\n",
            " [0.4263251 ]\n",
            " [0.46133503]\n",
            " [0.48884308]]\n",
            "\n"
          ]
        }
      ]
    }
  ]
}
