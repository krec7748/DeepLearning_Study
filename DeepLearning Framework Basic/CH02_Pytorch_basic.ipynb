{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CH02_Pytorch_basic\b.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPec0jYG/xDtIK6oU9scJy+"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Pytorch Basic\n"
      ],
      "metadata": {
        "id": "IsqQZKWj97oj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1. Pytorch import"
      ],
      "metadata": {
        "id": "lKPOe4di-JuQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "B27VSxiH9_xo"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BaRdOz7P-ZF8",
        "outputId": "9127f807-a30d-495c-b909-284e51020f6b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.10.0+cu111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2. Pytorch sneak peek"
      ],
      "metadata": {
        "id": "n-rKMMw3-oH4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Lambda, Compose\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use(\"seaborn\")"
      ],
      "metadata": {
        "id": "L1HQxfT5mFrY"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#MNIST dataset download\n",
        "train_data = datasets.MNIST(root = \"data\", train = True, download = True, transform = ToTensor())\n",
        "test_data = datasets.MNIST(root = \"data\", train = False, download = True, transform = ToTensor())"
      ],
      "metadata": {
        "id": "6LnwvXJy-dx9"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Set batch size\n",
        "batch_size = 64\n",
        "\n",
        "#Set dataloader\n",
        "train_dataloader = DataLoader(train_data, batch_size = batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size = batch_size)\n",
        "\n",
        "#Confirm\n",
        "for X, y in test_dataloader:\n",
        "    print(\"Shape of X [N, C, H, W]: \", X.shape)\n",
        "    print(\"Shape of y: \", y.shape)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqYTZYyMnFDM",
        "outputId": "27e6407b-4e0a-4826-9830-acd397d337cd"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X [N, C, H, W]:  torch.Size([64, 1, 28, 28])\n",
            "Shape of y:  torch.Size([64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Get GPU or CPU\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using {} device\".format(device))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2y7GG4uznzb_",
        "outputId": "84b7a8ea-e6fd-484b-9ad4-80804216adc1"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Set Model\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28 * 28, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(128, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlPWYLtSoJdi",
        "outputId": "6ed81d6e-1cf7-421b-f421-69969c826f3d"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Set Loss function, optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-3)"
      ],
      "metadata": {
        "id": "8FOC1XSC_cDo"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataloader.dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n66xN6uZpbMm",
        "outputId": "334b0a73-4f99-4d6d-8a7e-22b1ae14a98d"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Define function for training\n",
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        #Calculate loss\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        #Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}    [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "#Define function for test\n",
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss = loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "        test_loss /= num_batches\n",
        "        correct /= size\n",
        "        print(f\"Test Error: \\n Accuracy: {(100 * correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ],
      "metadata": {
        "id": "-48JJx2E_Q71"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training\n",
        "epochs = 10\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t + 1}\\n ----------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "    test(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOVASX9IAxMV",
        "outputId": "33942084-ca01-43d7-9c91-d0c4adb3d7cd"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            " ----------------------------------\n",
            "loss: 2.313183    [    0/60000]\n",
            "loss: 0.502830    [ 6400/60000]\n",
            "loss: 0.292958    [12800/60000]\n",
            "loss: 0.401551    [19200/60000]\n",
            "loss: 0.267273    [25600/60000]\n",
            "loss: 0.338681    [32000/60000]\n",
            "loss: 0.162210    [38400/60000]\n",
            "loss: 0.343527    [44800/60000]\n",
            "loss: 0.289648    [51200/60000]\n",
            "loss: 0.327219    [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 93.9%, Avg loss: 0.000513 \n",
            "\n",
            "Epoch 2\n",
            " ----------------------------------\n",
            "loss: 0.149147    [    0/60000]\n",
            "loss: 0.190234    [ 6400/60000]\n",
            "loss: 0.106685    [12800/60000]\n",
            "loss: 0.193552    [19200/60000]\n",
            "loss: 0.156662    [25600/60000]\n",
            "loss: 0.245390    [32000/60000]\n",
            "loss: 0.077120    [38400/60000]\n",
            "loss: 0.253082    [44800/60000]\n",
            "loss: 0.185872    [51200/60000]\n",
            "loss: 0.223239    [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.000169 \n",
            "\n",
            "Epoch 3\n",
            " ----------------------------------\n",
            "loss: 0.102374    [    0/60000]\n",
            "loss: 0.131363    [ 6400/60000]\n",
            "loss: 0.079185    [12800/60000]\n",
            "loss: 0.086692    [19200/60000]\n",
            "loss: 0.106866    [25600/60000]\n",
            "loss: 0.175968    [32000/60000]\n",
            "loss: 0.063022    [38400/60000]\n",
            "loss: 0.210804    [44800/60000]\n",
            "loss: 0.137504    [51200/60000]\n",
            "loss: 0.164110    [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.6%, Avg loss: 0.000078 \n",
            "\n",
            "Epoch 4\n",
            " ----------------------------------\n",
            "loss: 0.081721    [    0/60000]\n",
            "loss: 0.109150    [ 6400/60000]\n",
            "loss: 0.061457    [12800/60000]\n",
            "loss: 0.037566    [19200/60000]\n",
            "loss: 0.082939    [25600/60000]\n",
            "loss: 0.131511    [32000/60000]\n",
            "loss: 0.054640    [38400/60000]\n",
            "loss: 0.168306    [44800/60000]\n",
            "loss: 0.113407    [51200/60000]\n",
            "loss: 0.117448    [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 97.0%, Avg loss: 0.000031 \n",
            "\n",
            "Epoch 5\n",
            " ----------------------------------\n",
            "loss: 0.062087    [    0/60000]\n",
            "loss: 0.078546    [ 6400/60000]\n",
            "loss: 0.053951    [12800/60000]\n",
            "loss: 0.025368    [19200/60000]\n",
            "loss: 0.059075    [25600/60000]\n",
            "loss: 0.095091    [32000/60000]\n",
            "loss: 0.043964    [38400/60000]\n",
            "loss: 0.126217    [44800/60000]\n",
            "loss: 0.107436    [51200/60000]\n",
            "loss: 0.082396    [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 97.2%, Avg loss: 0.000016 \n",
            "\n",
            "Epoch 6\n",
            " ----------------------------------\n",
            "loss: 0.043283    [    0/60000]\n",
            "loss: 0.060632    [ 6400/60000]\n",
            "loss: 0.052342    [12800/60000]\n",
            "loss: 0.016211    [19200/60000]\n",
            "loss: 0.047928    [25600/60000]\n",
            "loss: 0.071084    [32000/60000]\n",
            "loss: 0.042415    [38400/60000]\n",
            "loss: 0.100285    [44800/60000]\n",
            "loss: 0.096536    [51200/60000]\n",
            "loss: 0.054806    [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 97.4%, Avg loss: 0.000010 \n",
            "\n",
            "Epoch 7\n",
            " ----------------------------------\n",
            "loss: 0.034912    [    0/60000]\n",
            "loss: 0.041698    [ 6400/60000]\n",
            "loss: 0.053306    [12800/60000]\n",
            "loss: 0.014507    [19200/60000]\n",
            "loss: 0.036308    [25600/60000]\n",
            "loss: 0.050268    [32000/60000]\n",
            "loss: 0.029360    [38400/60000]\n",
            "loss: 0.072684    [44800/60000]\n",
            "loss: 0.091235    [51200/60000]\n",
            "loss: 0.030167    [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 97.5%, Avg loss: 0.000005 \n",
            "\n",
            "Epoch 8\n",
            " ----------------------------------\n",
            "loss: 0.028717    [    0/60000]\n",
            "loss: 0.028573    [ 6400/60000]\n",
            "loss: 0.054282    [12800/60000]\n",
            "loss: 0.014425    [19200/60000]\n",
            "loss: 0.028863    [25600/60000]\n",
            "loss: 0.042255    [32000/60000]\n",
            "loss: 0.022714    [38400/60000]\n",
            "loss: 0.051213    [44800/60000]\n",
            "loss: 0.087913    [51200/60000]\n",
            "loss: 0.023063    [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 97.7%, Avg loss: 0.000003 \n",
            "\n",
            "Epoch 9\n",
            " ----------------------------------\n",
            "loss: 0.023963    [    0/60000]\n",
            "loss: 0.023824    [ 6400/60000]\n",
            "loss: 0.051713    [12800/60000]\n",
            "loss: 0.012831    [19200/60000]\n",
            "loss: 0.020300    [25600/60000]\n",
            "loss: 0.018381    [32000/60000]\n",
            "loss: 0.014699    [38400/60000]\n",
            "loss: 0.038461    [44800/60000]\n",
            "loss: 0.078352    [51200/60000]\n",
            "loss: 0.013702    [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 97.6%, Avg loss: 0.000002 \n",
            "\n",
            "Epoch 10\n",
            " ----------------------------------\n",
            "loss: 0.018744    [    0/60000]\n",
            "loss: 0.016373    [ 6400/60000]\n",
            "loss: 0.049977    [12800/60000]\n",
            "loss: 0.012253    [19200/60000]\n",
            "loss: 0.012095    [25600/60000]\n",
            "loss: 0.014040    [32000/60000]\n",
            "loss: 0.010782    [38400/60000]\n",
            "loss: 0.026904    [44800/60000]\n",
            "loss: 0.062822    [51200/60000]\n",
            "loss: 0.008794    [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 97.6%, Avg loss: 0.000001 \n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "#Input new test image\n",
        "\n",
        "#Set path of image file\n",
        "cur_dir = os.getcwd()\n",
        "img_path = os.path.join(cur_dir, \"image.png\")\n",
        "\n",
        "#Read image file\n",
        "cur_img = Image.open(img_path)\n",
        "\n",
        "#Resize\n",
        "cur_img = cur_img.resize((28, 28))\n",
        "image = np.asarray(cur_img)\n",
        "\n",
        "#If image channel is RGB, change it to gray scale\n",
        "try:\n",
        "    image = np.mean(image , axis = 2)\n",
        "except:\n",
        "    pass\n",
        "\n",
        "#Change to black background and white character like MNIST data\n",
        "image = np.abs(255 - image)\n",
        "\n",
        "#Normalization\n",
        "image = image.astype(np.float32) / 255.\n",
        "\n",
        "#Confirm\n",
        "plt.figure(figsize = (5, 5))\n",
        "plt.imshow(image, cmap = \"gray\")\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "efF74yttwrk-",
        "outputId": "3b216e7f-49e8-43cd-ff55-07a92ec38bae"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAATAAAAEvCAYAAADCe529AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAASHUlEQVR4nO3de2zN9x/H8deZauiwVmlFFjNGMJpsQZS4lGYLsbgtLnXZFsmwENcY4rLFopTI3BJ0JpvGdpb+JRlrZyITqqbbbDVJdRtrRKqlqKlbnd8fy5ofun4/jnPx5vlIvn/47vX7nPfJN3n9zuVzvvUFAoGAAMCgZ6I9AAAEiwIDYBYFBsAsCgyAWRQYALMoMABmxUTiQXw+XyQeBsATqKGdXkEX2KpVq3TixAn5fD4tWbJEKSkpwS4FAMEJBKGwsDDw7rvvBgKBQKC0tDQwduzYBvOSODg4OII6GhLUZ2AFBQVKT0+XJHXs2FFXrlzRtWvXglkKAIIWVIFVVlYqISGh7t8tW7ZURUVFyIYCABch+RaSn1MCiIagCiwpKUmVlZV1/75w4YJat24dsqEAwEVQBdavXz/l5eVJkk6ePKmkpCQ1a9YspIMBgJegtlG8+uqrevnllzV+/Hj5fD6tWLEi1HMBgCdfJO4HxkZWAMFqqKL4KREAsygwAGZRYADMosAAmEWBATCLAgNgFgUGwCwKDIBZFBgAsygwAGZRYADMosAAmEWBATCLAgNgFgUGwCwKDIBZFBgAsygwAGZRYADMosAAmEWBATCLAgNgFgUGwCwKDIBZFBgAsygwAGZRYADMosAAmEWBATArJtoDIDK6d+/ulBsyZIhTrnPnzp6Z5s2bO6115swZp1xeXp5n5vDhw05r4cnAKzAAZlFgAMyiwACYRYEBMIsCA2AWBQbALAoMgFkUGACzKDAAZvkCgUAg7A/i84X7IZ5aM2fOdMqtX7/eKde4cWOn3M2bNz0z169fd1orISHBKediyZIlTrnMzMyQPSbCq6GKCuqnRIWFhZo9e7Y6deok6Z+flSxbtiy46QAgSEH/FrJ3797auHFjKGcBgIfCZ2AAzAq6wEpLSzV9+nRNmDCBOwAAiIqg3kK2b99eM2fO1NChQ1VWVqYpU6YoPz9fsbGxoZ4PAP5TUK/AkpOTNWzYMPl8PrVr106tWrVSeXl5qGcDgAYFVWB79uzRjh07JEkVFRW6ePGikpOTQzoYAHgJ6i3k4MGDtWDBAn333Xe6ffu2PvjgA94+Aog4NrI+xlxuA338+HGntX799Ven3Ny5c51yf/zxh2fm2rVrTmt16NDBKbdlyxbPTEpKitNaXbp0ccqdO3fOKYfwaaii2EYBwCwKDIBZFBgAsygwAGZRYADMosAAmEWBATCLAgNgFgUGwKygb2iI8Js4caJnxvUnXNOnT3fKFRUVOeVC6eeff3bKbdq0yTPzxRdfOK3Vs2dPpxw78R9vvAIDYBYFBsAsCgyAWRQYALMoMABmUWAAzKLAAJhFgQEwiwIDYBY78R9j3bp188xcvnzZaa2SkpJHHSfqSktLQ7ZWQkJCyNZC9PAKDIBZFBgAsygwAGZRYADMosAAmEWBATCLAgNgFgUGwCw2sj7GXG5n/Oyzzzqt1axZM6dcdXW1Uy4akpOTQ7bW33//HbK1ED28AgNgFgUGwCwKDIBZFBgAsygwAGZRYADMosAAmEWBATCLAgNgFjvxH2M//vijZ2bGjBlOa40ePdopt2XLFqdcNAwfPjxka506dSpkayF6nF6BlZSUKD09XTk5OZKk8+fPa/LkycrIyNDs2bN169atsA4JAPXxLLDr169r5cqVSk1NrTu3ceNGZWRkaPfu3XrhhReUm5sb1iEBoD6eBRYbG6vs7GwlJSXVnSssLNSQIUMkSWlpaSooKAjfhADwHzw/A4uJiVFMzL2xmpoaxcbGSpISExNVUVERnukAoAGP/C1kIBAIxRwA8NCCKrC4uDjduHFDklReXn7P20sAiJSgCqxv377Ky8uTJOXn56t///4hHQoAXHh+BlZcXKw1a9bo3LlziomJUV5entatW6dFixbJ7/erbdu2GjlyZCRmBYB7eBZY9+7dtWvXrgfO79y5MywDAYArXyACn8L7fL5wP8QT6bnnnvPMHDp0yGmt9u3bO+UWL17slPvyyy89M3fv3nVaa9CgQU653bt3e2aOHDnitNbrr7/ulLtz545TDuHTUEXxW0gAZlFgAMyiwACYRYEBMIsCA2AWBQbALAoMgFkUGACzKDAAZrET37ju3bs75fbt2+eUe/75551yFy5c8My47sRv06aNU+7s2bOemfT0dKe1SktLnXKIPnbiA3giUWAAzKLAAJhFgQEwiwIDYBYFBsAsCgyAWRQYALM874mP6Ln/DwrXZ+DAgU5rxcfHP+o490hISPDMNG7cOKSPWVtb65lxvT31xYsXnXJVVVVOOUQHr8AAmEWBATCLAgNgFgUGwCwKDIBZFBgAsygwAGZRYADMosAAmMUtpaPgmWfc/n9j+/btnpmpU6c6rVVYWOiUW7FihVPuzJkznplu3bo5rdW/f3+n3PDhwz0znTp1clrrr7/+csp99NFHTrns7GynHB4et5QG8ESiwACYRYEBMIsCA2AWBQbALAoMgFkUGACzKDAAZlFgAMxiJ34UuO6e/+STTzwzn332mdNaM2bMcMrV1NQ45aKhWbNmnpnRo0c7rTV//nynXEpKilPu448/Dtlj3r171yn3tHjknfglJSVKT09XTk6OJGnRokV64403NHnyZE2ePFkHDx4MyaAA8DA8/+zN9evXtXLlSqWmpt5zft68eUpLSwvbYADgxfMVWGxsrLKzs5WUlBSJeQDAmWeBxcTEqEmTJg+cz8nJ0ZQpUzR37lxdunQpLMMBQEOC+hZyxIgRWrBggT7//HN17dpVmzdvDvVcAOApqAJLTU1V165dJUmDBw9WSUlJSIcCABdBFdisWbNUVlYm6Z8b5bneRA4AQsnzW8ji4mKtWbNG586dU0xMjPLy8jRp0iTNmTNHTZs2VVxcnDIzMyMxKwDcg42sIdS0aVOn3C+//OKUq62t9cz06tXLaa3q6mqn3NOiefPmTrmtW7c65TIyMjwz48aNc1rrq6++cso9LbilNIAnEgUGwCwKDIBZFBgAsygwAGZRYADMosAAmEWBATCLAgNgFjvxQ6hnz55OuR9++MEp9/7773tmsrKynNZCcBISEpxyf/75p2cmPz/faa2xY8c65Z4W7MQH8ESiwACYRYEBMIsCA2AWBQbALAoMgFkUGACzKDAAZlFgAMzy/KMecOe6a9vVlStXQroeHp7L3yWQGt4t/q+bN28+6ji4D6/AAJhFgQEwiwIDYBYFBsAsCgyAWRQYALMoMABmUWAAzKLAAJjFTvwQKioqcsqdPXvWKTd//nzPzJ49e5zWOn/+vFMO9xo0aJBTLj4+3jNz8ODBRxsGD+AVGACzKDAAZlFgAMyiwACYRYEBMIsCA2AWBQbALAoMgFm+gMu9cB/1QXy+cD+EKWPGjHHK5ebmemaKi4ud1lq4cKFTbt++fU4569q1a+eU+/rrr51yycnJnpnu3bs7rXXhwgWn3NOioYpy2omflZWloqIi3blzR9OmTVOPHj20cOFC1dbWqnXr1lq7dq1iY2NDNjAAuPAssKNHj+r06dPy+/2qqqrSqFGjlJqaqoyMDA0dOlTr169Xbm6uMjIyIjEvANTx/AysV69e2rBhgySpRYsWqqmpUWFhoYYMGSJJSktLU0FBQXinBIB6eBZYo0aNFBcXJ+mfz2QGDBigmpqaureMiYmJqqioCO+UAFAP528h9+/fr9zcXC1fvvye8xH4DgAA6uVUYIcOHdLWrVuVnZ2t5s2bKy4uTjdu3JAklZeXKykpKaxDAkB9PAusurpaWVlZ2rZtW909j/r27au8vDxJUn5+vvr37x/eKQGgHp7fQu7du1dVVVWaM2dO3bnVq1dr6dKl8vv9atu2rUaOHBnWIQGgPp4FNm7cOI0bN+6B8zt37gzLQADgip34j7F33nnHM7Nu3TqntVq2bOmUO3LkiFPum2++8cycOnXKaa3Lly875Vy88sorTrm5c+c65dq0aeOUe+uttzwzu3btcloL92qoovgtJACzKDAAZlFgAMyiwACYRYEBMIsCA2AWBQbALAoMgFkUGACz2IlvXNu2bZ1yM2bMcMqNHz/eKffSSy855R5XP/30k1Nu8eLFTrl/b26A0GMnPoAnEgUGwCwKDIBZFBgAsygwAGZRYADMosAAmEWBATCLjay4R5MmTZxyHTp08My0a9cupI/porKy0il37Ngxp9ytW7ceZRyEABtZATyRKDAAZlFgAMyiwACYRYEBMIsCA2AWBQbALAoMgFkUGACz2IkP4LHGTnwATyQKDIBZFBgAsygwAGZRYADMosAAmEWBATCLAgNgFgUGwCwKDIBZMS6hrKwsFRUV6c6dO5o2bZoOHDigkydPKj4+XpI0depUDRo0KJxzAsADPAvs6NGjOn36tPx+v6qqqjRq1Cj16dNH8+bNU1paWiRmBIB6eRZYr169lJKSIklq0aKFampqVFtbG/bBAMDLQ92Nwu/36/jx42rUqJEqKip0+/ZtJSYmatmyZWrZsuV/Pwh3owAQpAYrKuDo22+/Dbz55puBq1evBo4cORL47bffAoFAILBt27bAhx9+2OD/VhIHBwdHUEeD3eJSXt9//31gzJgxgaqqqgf+2+nTpwMTJ06kwDg4OMJyNMRzG0V1dbWysrK0bdu2um8dZ82apbKyMklSYWGhOnXq5LUMAISc54f4e/fuVVVVlebMmVN3bvTo0ZozZ46aNm2quLg4ZWZmhnVIAKgPt5QG8FhrqKLYiQ/ALAoMgFkUGACzKDAAZlFgAMyiwACYRYEBMIsCA2AWBQbALAoMgFkUGACzKDAAZlFgAMyiwACYRYEBMIsCA2AWBQbALAoMgFkUGACzPP+oRyhE4Lb7AJ5CvAIDYBYFBsAsCgyAWRQYALMoMABmUWAAzIrINor7rVq1SidOnJDP59OSJUuUkpISjTGCUlhYqNmzZ6tTp06SpM6dO2vZsmVRnspNSUmJ3nvvPb399tuaNGmSzp8/r4ULF6q2tlatW7fW2rVrFRsbG+0xG3T/c1i0aJFOnjyp+Ph4SdLUqVM1aNCg6A7ZgKysLBUVFenOnTuaNm2aevToYe4a3P8cDhw4ELVrEPECO3bsmM6ePSu/36/ff/9dS5Yskd/vj/QYj6R3797auHFjtMd4KNevX9fKlSuVmppad27jxo3KyMjQ0KFDtX79euXm5iojIyOKUzasvucgSfPmzVNaWlqUpnJ39OhRnT59Wn6/X1VVVRo1apRSU1NNXYP6nkOfPn2idg0i/hayoKBA6enpkqSOHTvqypUrunbtWqTHeOrExsYqOztbSUlJdecKCws1ZMgQSVJaWpoKCgqiNZ6T+p6DJb169dKGDRskSS1atFBNTY25a1Dfc6itrY3aPBEvsMrKSiUkJNT9u2XLlqqoqIj0GI+ktLRU06dP14QJE3T48OFoj+MkJiZGTZo0uedcTU1N3duVxMTEx/461PccJCknJ0dTpkzR3LlzdenSpShM5qZRo0aKi4uTJOXm5mrAgAHmrkF9z6FRo0ZRuwZR+Qzs/1n7mVH79u01c+ZMDR06VGVlZZoyZYry8/Mf+88tvFi7Dv8aMWKE4uPj1bVrV23fvl2bN2/W8uXLoz1Wg/bv36/c3Fx9+umneu211+rOW7oG//8ciouLo3YNIv4KLCkpSZWVlXX/vnDhglq3bh3pMYKWnJysYcOGyefzqV27dmrVqpXKy8ujPVZQ4uLidOPGDUlSeXm5ybdmqamp6tq1qyRp8ODBKikpifJEDTt06JC2bt2q7OxsNW/e3OQ1uP85RPMaRLzA+vXrp7y8PEnSyZMnlZSUpGbNmkV6jKDt2bNHO3bskCRVVFTo4sWLSk5OjvJUwenbt2/dtcjPz1f//v2jPNHDmzVrlsrKyiT985nev98OP46qq6uVlZWlbdu21X1jZ+0a1PcconkNfIEovG5dt26djh8/Lp/PpxUrVqhLly6RHiFo165d04IFC3T16lXdvn1bM2fO1MCBA6M9lqfi4mKtWbNG586dU0xMjJKTk7Vu3TotWrRIN2/eVNu2bZWZmanGjRtHe9T/VN9zmDRpkrZv366mTZsqLi5OmZmZSkxMjPao9fL7/dq0aZNefPHFunOrV6/W0qVLzVyD+p7D6NGjlZOTE5VrEJUCA4BQYCc+ALMoMABmUWAAzKLAAJhFgQEwiwIDYBYFBsAsCgyAWf8DnMZf6Z3CEuYAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Predict\n",
        "image = torch.as_tensor(image).to(device).reshape(1, 1, 28, 28)\n",
        "model.eval()\n",
        "predict = model(image)\n",
        "\n",
        "print(\"Model이 예측한 값은 {} 입니다.\".format(predict.argmax(1).item()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fc15A6vFBgXe",
        "outputId": "5d4fd910-120f-44f9-f055-a522829358e3"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model이 예측한 값은 8 입니다.\n"
          ]
        }
      ]
    }
  ]
}